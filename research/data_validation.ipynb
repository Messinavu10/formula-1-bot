{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/naveenkumar/Desktop/formula-1-bot'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/naveenkumar/Desktop/formula-1-bot\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.formula_one.config.configuration import ConfigurationManager\n",
    "# from src.formula_one.entity.config_entity import DataValidationConfig, DatabaseConfig\n",
    "# from src.formula_one.components.data_ingestion import DatabaseIngestion\n",
    "# from src.formula_one.logging import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "from src.formula_one.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    \"\"\"Configuration for data validation\"\"\"\n",
    "    root_dir: Path\n",
    "    validation_report_dir: Path\n",
    "    data_quality_threshold: float = 0.90  # Minimum acceptable data quality\n",
    "    missing_value_threshold: float = 0.25  # Maximum acceptable missing values\n",
    "    outlier_threshold: float = 3.0         # Standard deviations for outlier detection\n",
    "    \n",
    "    # Tables to validate\n",
    "    tables_to_validate: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.tables_to_validate is None:\n",
    "            self.tables_to_validate = [\n",
    "                \"meetings\", \"sessions\", \"drivers\", \"laps\", \n",
    "                \"pit_stops\", \"stints\", \"positions\", \"intervals\", \n",
    "                \"weather\", \"race_control\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formula_one.constants import *\n",
    "from src.formula_one.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"Manages configuration loading from YAML files\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file_path: str = \"config/config.yaml\"):\n",
    "        self.config_file_path = Path(config_file_path)\n",
    "        self.config = read_yaml(self.config_file_path)\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        \"\"\"Get data validation configuration\"\"\"\n",
    "        config_data = self.config.get('data_validation', {})\n",
    "        \n",
    "        return DataValidationConfig(\n",
    "            root_dir=Path(config_data.get('root_dir', 'artifacts/data_validation')),\n",
    "            validation_report_dir=Path(config_data.get('validation_report_dir', 'artifacts/data_validation/reports')),\n",
    "            data_quality_threshold=config_data.get('data_quality_threshold', 0.95),\n",
    "            missing_value_threshold=config_data.get('missing_value_threshold', 0.1),\n",
    "            outlier_threshold=config_data.get('outlier_threshold', 3.0),\n",
    "            tables_to_validate=config_data.get('tables_to_validate', [\n",
    "                \"meetings\", \"sessions\", \"drivers\", \"laps\", \n",
    "                \"pit_stops\", \"stints\", \"positions\", \"intervals\", \n",
    "                \"weather\", \"race_control\"\n",
    "            ])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formula_one.entity.config_entity import DataValidationConfig, DatabaseConfig\n",
    "from src.formula_one.components.data_ingestion import DatabaseIngestion\n",
    "\n",
    "class DataValidation:\n",
    "    \"\"\"Handles data validation for F1 data\"\"\"\n",
    "    \n",
    "    def __init__(self, validation_config: DataValidationConfig, db_config: DatabaseConfig):\n",
    "        self.validation_config = validation_config\n",
    "        self.db_config = db_config\n",
    "        self.logger = logger\n",
    "        self.db_ingestion = DatabaseIngestion(None, db_config, None)  # Just for DB connection\n",
    "    \n",
    "    def validate_all_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"Validate all tables in the database\"\"\"\n",
    "        self.logger.info(\"Starting comprehensive data validation\")\n",
    "        \n",
    "        validation_results = {}\n",
    "        \n",
    "        for table in self.validation_config.tables_to_validate:\n",
    "            self.logger.info(f\"Validating table: {table}\")\n",
    "            validation_results[table] = self.validate_table(table)\n",
    "        \n",
    "        # Overall validation summary\n",
    "        overall_status = self._generate_validation_summary(validation_results)\n",
    "        validation_results['overall'] = overall_status\n",
    "        \n",
    "        return validation_results\n",
    "    \n",
    "    def validate_table(self, table_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Validate a specific table\"\"\"\n",
    "        conn = self.db_ingestion.connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            # Get table data\n",
    "            cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "            if not data:\n",
    "                return {\n",
    "                    'status': 'EMPTY',\n",
    "                    'row_count': 0,\n",
    "                    'missing_values': {},\n",
    "                    'data_types': {},\n",
    "                    'outliers': {},\n",
    "                    'issues': ['Table is empty']\n",
    "                }\n",
    "            \n",
    "            # Convert to DataFrame for easier analysis\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "            validation_result = {\n",
    "                'row_count': len(df),\n",
    "                'missing_values': self._check_missing_values(df),\n",
    "                'data_types': self._check_data_types(df),\n",
    "                'outliers': self._check_outliers(df, table_name),\n",
    "                'duplicates': self._check_duplicates(df),\n",
    "                'foreign_keys': self._check_foreign_keys(df, table_name),\n",
    "                'issues': []\n",
    "            }\n",
    "            \n",
    "            # Determine overall status\n",
    "            validation_result['status'] = self._determine_table_status(validation_result)\n",
    "            \n",
    "            return validation_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error validating table {table_name}: {e}\")\n",
    "            return {\n",
    "                'status': 'ERROR',\n",
    "                'issues': [f\"Validation error: {str(e)}\"]\n",
    "            }\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def _check_missing_values(self, df: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Check missing values in each column\"\"\"\n",
    "        missing_percentages = {}\n",
    "        for column in df.columns:\n",
    "            missing_count = df[column].isnull().sum()\n",
    "            missing_percentage = missing_count / len(df)\n",
    "            missing_percentages[column] = missing_percentage\n",
    "            \n",
    "            if missing_percentage > self.validation_config.missing_value_threshold:\n",
    "                self.logger.warning(f\"High missing values in {column}: {missing_percentage:.2%}\")\n",
    "        \n",
    "        return missing_percentages\n",
    "    \n",
    "    def _check_data_types(self, df: pd.DataFrame) -> Dict[str, str]:\n",
    "        \"\"\"Check data types of each column\"\"\"\n",
    "        return {column: str(dtype) for column, dtype in df.dtypes.items()}\n",
    "    \n",
    "    def _check_outliers(self, df: pd.DataFrame, table_name: str) -> Dict[str, List]:\n",
    "        \"\"\"Check for outliers in numerical columns\"\"\"\n",
    "        outliers = {}\n",
    "        \n",
    "        for column in df.select_dtypes(include=[np.number]).columns:\n",
    "            if column in ['id', 'created_at']:  # Skip metadata columns\n",
    "                continue\n",
    "                \n",
    "            Q1 = df[column].quantile(0.25)\n",
    "            Q3 = df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outlier_indices = df[(df[column] < lower_bound) | (df[column] > upper_bound)].index.tolist()\n",
    "            \n",
    "            if outlier_indices:\n",
    "                outliers[column] = outlier_indices\n",
    "                self.logger.warning(f\"Found {len(outlier_indices)} outliers in {table_name}.{column}\")\n",
    "        \n",
    "        return outliers\n",
    "    \n",
    "    def _check_duplicates(self, df: pd.DataFrame) -> Dict[str, int]:\n",
    "        \"\"\"Check for duplicate rows\"\"\"\n",
    "        duplicates = df.duplicated().sum()\n",
    "        return {'duplicate_rows': duplicates}\n",
    "    \n",
    "    def _check_foreign_keys(self, df: pd.DataFrame, table_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Check foreign key relationships\"\"\"\n",
    "        # This is a simplified check - you might want more sophisticated FK validation\n",
    "        fk_checks = {}\n",
    "        \n",
    "        if 'meeting_key' in df.columns:\n",
    "            fk_checks['meeting_key'] = {\n",
    "                'unique_values': df['meeting_key'].nunique(),\n",
    "                'null_count': df['meeting_key'].isnull().sum()\n",
    "            }\n",
    "        \n",
    "        if 'session_key' in df.columns:\n",
    "            fk_checks['session_key'] = {\n",
    "                'unique_values': df['session_key'].nunique(),\n",
    "                'null_count': df['session_key'].isnull().sum()\n",
    "            }\n",
    "        \n",
    "        return fk_checks\n",
    "    \n",
    "    def _determine_table_status(self, validation_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Determine overall status of table validation\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check missing values\n",
    "        for column, missing_pct in validation_result['missing_values'].items():\n",
    "            if missing_pct > self.validation_config.missing_value_threshold:\n",
    "                issues.append(f\"High missing values in {column}\")\n",
    "        \n",
    "        # Check duplicates\n",
    "        if validation_result['duplicates']['duplicate_rows'] > 0:\n",
    "            issues.append(\"Duplicate rows found\")\n",
    "        \n",
    "        # Check outliers\n",
    "        if validation_result['outliers']:\n",
    "            issues.append(\"Outliers detected\")\n",
    "        \n",
    "        if not issues:\n",
    "            return 'PASS'\n",
    "        elif len(issues) <= 2:\n",
    "            return 'WARNING'\n",
    "        else:\n",
    "            return 'FAIL'\n",
    "    \n",
    "    def _generate_validation_summary(self, validation_results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate overall validation summary\"\"\"\n",
    "        total_tables = len([k for k in validation_results.keys() if k != 'overall'])\n",
    "        passed_tables = len([v for v in validation_results.values() if isinstance(v, dict) and v.get('status') == 'PASS'])\n",
    "        failed_tables = len([v for v in validation_results.values() if isinstance(v, dict) and v.get('status') == 'FAIL'])\n",
    "        \n",
    "        overall_status = 'PASS' if failed_tables == 0 else 'FAIL'\n",
    "        \n",
    "        return {\n",
    "            'status': overall_status,\n",
    "            'total_tables': total_tables,\n",
    "            'passed_tables': passed_tables,\n",
    "            'failed_tables': failed_tables,\n",
    "            'pass_rate': passed_tables / total_tables if total_tables > 0 else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 13:04:10,898: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-03 13:04:10,900: INFO: 2071959291: Starting comprehensive data validation]\n",
      "[2025-07-03 13:04:10,901: INFO: 2071959291: Validating table: meetings]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 13:04:10,991: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,004: INFO: 2071959291: Validating table: sessions]\n",
      "[2025-07-03 13:04:11,007: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,015: WARNING: 2071959291: Found 5 outliers in sessions.session_key]\n",
      "[2025-07-03 13:04:11,016: INFO: 2071959291: Validating table: drivers]\n",
      "[2025-07-03 13:04:11,019: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,025: WARNING: 2071959291: Found 100 outliers in drivers.session_key]\n",
      "[2025-07-03 13:04:11,029: INFO: 2071959291: Validating table: laps]\n",
      "[2025-07-03 13:04:11,032: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,102: WARNING: 2071959291: High missing values in lap_duration: 10.12%]\n",
      "[2025-07-03 13:04:11,105: WARNING: 2071959291: Found 2553 outliers in laps.session_key]\n",
      "[2025-07-03 13:04:11,107: WARNING: 2071959291: Found 946 outliers in laps.lap_number]\n",
      "[2025-07-03 13:04:11,108: WARNING: 2071959291: Found 2303 outliers in laps.lap_duration]\n",
      "[2025-07-03 13:04:11,109: WARNING: 2071959291: Found 1771 outliers in laps.duration_sector_1]\n",
      "[2025-07-03 13:04:11,110: WARNING: 2071959291: Found 572 outliers in laps.duration_sector_2]\n",
      "[2025-07-03 13:04:11,111: WARNING: 2071959291: Found 1117 outliers in laps.duration_sector_3]\n",
      "[2025-07-03 13:04:11,118: INFO: 2071959291: Validating table: pit_stops]\n",
      "[2025-07-03 13:04:11,122: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,140: WARNING: 2071959291: High missing values in pit_duration: 22.23%]\n",
      "[2025-07-03 13:04:11,142: WARNING: 2071959291: Found 450 outliers in pit_stops.session_key]\n",
      "[2025-07-03 13:04:11,143: WARNING: 2071959291: Found 211 outliers in pit_stops.lap_number]\n",
      "[2025-07-03 13:04:11,144: WARNING: 2071959291: Found 124 outliers in pit_stops.pit_duration]\n",
      "[2025-07-03 13:04:11,147: INFO: 2071959291: Validating table: stints]\n",
      "[2025-07-03 13:04:11,151: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,162: WARNING: 2071959291: Found 474 outliers in stints.session_key]\n",
      "[2025-07-03 13:04:11,164: WARNING: 2071959291: Found 164 outliers in stints.lap_start]\n",
      "[2025-07-03 13:04:11,164: WARNING: 2071959291: Found 350 outliers in stints.lap_end]\n",
      "[2025-07-03 13:04:11,165: WARNING: 2071959291: Found 423 outliers in stints.tyre_age_at_start]\n",
      "[2025-07-03 13:04:11,166: INFO: 2071959291: Validating table: positions]\n",
      "[2025-07-03 13:04:11,171: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,247: WARNING: 2071959291: Found 3019 outliers in positions.session_key]\n",
      "[2025-07-03 13:04:11,253: INFO: 2071959291: Validating table: intervals]\n",
      "[2025-07-03 13:04:11,260: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,793: WARNING: 2071959291: Found 18965 outliers in intervals.session_key]\n",
      "[2025-07-03 13:04:11,811: WARNING: 2071959291: Found 1125 outliers in intervals.gap_to_leader]\n",
      "[2025-07-03 13:04:11,820: WARNING: 2071959291: Found 26672 outliers in intervals.interval]\n",
      "[2025-07-03 13:04:11,885: INFO: 2071959291: Validating table: weather]\n",
      "[2025-07-03 13:04:11,891: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,912: WARNING: 2071959291: Found 493 outliers in weather.session_key]\n",
      "[2025-07-03 13:04:11,915: WARNING: 2071959291: Found 313 outliers in weather.track_temperature]\n",
      "[2025-07-03 13:04:11,916: INFO: 2071959291: Validating table: race_control]\n",
      "[2025-07-03 13:04:11,920: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 13:04:11,929: WARNING: 2071959291: High missing values in driver_number: 85.41%]\n",
      "[2025-07-03 13:04:11,930: WARNING: 2071959291: High missing values in flag: 45.59%]\n",
      "[2025-07-03 13:04:11,930: WARNING: 2071959291: High missing values in lap_number: 51.01%]\n",
      "[2025-07-03 13:04:11,930: WARNING: 2071959291: High missing values in scope: 45.59%]\n",
      "[2025-07-03 13:04:11,931: WARNING: 2071959291: High missing values in sector: 71.43%]\n",
      "[2025-07-03 13:04:11,932: WARNING: 2071959291: Found 219 outliers in race_control.session_key]\n",
      "=== DATA VALIDATION RESULTS ===\n",
      "Overall Status: FAIL\n",
      "Pass Rate: 10.00%\n",
      "Passed Tables: 1/10\n",
      "\n",
      "=== DETAILED RESULTS ===\n",
      "\n",
      "MEETINGS:\n",
      "  Status: PASS\n",
      "  Rows: 12\n",
      "  Issues: 0\n",
      "\n",
      "SESSIONS:\n",
      "  Status: WARNING\n",
      "  Rows: 53\n",
      "  Issues: 0\n",
      "\n",
      "DRIVERS:\n",
      "  Status: WARNING\n",
      "  Rows: 1059\n",
      "  Issues: 0\n",
      "\n",
      "LAPS:\n",
      "  Status: WARNING\n",
      "  Rows: 29981\n",
      "  Issues: 0\n",
      "  Missing Values:\n",
      "    lap_duration: 10.12%\n",
      "    duration_sector_1: 8.44%\n",
      "    duration_sector_2: 0.75%\n",
      "    duration_sector_3: 5.82%\n",
      "\n",
      "PIT_STOPS:\n",
      "  Status: WARNING\n",
      "  Rows: 4206\n",
      "  Issues: 0\n",
      "  Missing Values:\n",
      "    pit_duration: 22.23%\n",
      "\n",
      "STINTS:\n",
      "  Status: WARNING\n",
      "  Rows: 4522\n",
      "  Issues: 0\n",
      "  Missing Values:\n",
      "    compound: 0.18%\n",
      "    lap_start: 0.13%\n",
      "    lap_end: 0.13%\n",
      "\n",
      "POSITIONS:\n",
      "  Status: WARNING\n",
      "  Rows: 36834\n",
      "  Issues: 0\n",
      "\n",
      "INTERVALS:\n",
      "  Status: WARNING\n",
      "  Rows: 288343\n",
      "  Issues: 0\n",
      "  Missing Values:\n",
      "    gap_to_leader: 9.27%\n",
      "    interval: 1.41%\n",
      "\n",
      "WEATHER:\n",
      "  Status: WARNING\n",
      "  Rows: 5119\n",
      "  Issues: 0\n",
      "\n",
      "RACE_CONTROL:\n",
      "  Status: FAIL\n",
      "  Rows: 2268\n",
      "  Issues: 0\n",
      "  Missing Values:\n",
      "    driver_number: 85.41%\n",
      "    flag: 45.59%\n",
      "    lap_number: 51.01%\n",
      "    scope: 45.59%\n",
      "    sector: 71.43%\n"
     ]
    }
   ],
   "source": [
    " # Load configuration\n",
    "config_manager = ConfigurationManager()\n",
    "validation_config = config_manager.get_data_validation_config()\n",
    "db_config = DatabaseConfig()\n",
    "\n",
    "# Create validation instance\n",
    "data_validation = DataValidation(validation_config, db_config)\n",
    "\n",
    "# Run validation\n",
    "validation_results = data_validation.validate_all_data()\n",
    "\n",
    "# Print results\n",
    "print(\"=== DATA VALIDATION RESULTS ===\")\n",
    "print(f\"Overall Status: {validation_results['overall']['status']}\")\n",
    "print(f\"Pass Rate: {validation_results['overall']['pass_rate']:.2%}\")\n",
    "print(f\"Passed Tables: {validation_results['overall']['passed_tables']}/{validation_results['overall']['total_tables']}\")\n",
    "\n",
    "print(\"\\n=== DETAILED RESULTS ===\")\n",
    "for table, result in validation_results.items():\n",
    "    if table != 'overall':\n",
    "        print(f\"\\n{table.upper()}:\")\n",
    "        print(f\"  Status: {result.get('status', 'UNKNOWN')}\")\n",
    "        print(f\"  Rows: {result.get('row_count', 0)}\")\n",
    "        print(f\"  Issues: {len(result.get('issues', []))}\")\n",
    "        \n",
    "        # Show missing values\n",
    "        missing_values = result.get('missing_values', {})\n",
    "        if any(pct > 0 for pct in missing_values.values()):\n",
    "            print(\"  Missing Values:\")\n",
    "            for col, pct in missing_values.items():\n",
    "                if pct > 0:\n",
    "                    print(f\"    {col}: {pct:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
