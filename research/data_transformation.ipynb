{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/naveenkumar/Desktop/formula-1-bot'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/naveenkumar/Desktop/formula-1-bot\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formula_one.logging import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any, Optional\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    \"\"\"Configuration for data transformation\"\"\"\n",
    "    root_dir: Path\n",
    "    transformed_data_dir: Path\n",
    "    cleaned_data_dir: Path\n",
    "    \n",
    "    # Data cleaning settings\n",
    "    missing_value_strategy: str = \"impute\"\n",
    "    outlier_strategy: str = \"context_aware\"\n",
    "    outlier_threshold: float = 3.0\n",
    "    \n",
    "    # Feature engineering settings\n",
    "    create_tire_features: bool = True\n",
    "    create_lap_features: bool = True\n",
    "    create_weather_features: bool = True\n",
    "    create_driver_features: bool = True\n",
    "    \n",
    "    # Data type settings\n",
    "    numeric_columns: List[str] = None\n",
    "    categorical_columns: List[str] = None\n",
    "    datetime_columns: List[str] = None\n",
    "    \n",
    "    # Tables to transform\n",
    "    tables_to_transform: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.tables_to_transform is None:\n",
    "            self.tables_to_transform = [\n",
    "                \"sessions\", \"drivers\", \"laps\", \n",
    "                \"pit_stops\", \"stints\", \"positions\", \"intervals\", \n",
    "                \"weather\"\n",
    "            ]\n",
    "        \n",
    "        if self.numeric_columns is None:\n",
    "            self.numeric_columns = [\n",
    "                \"lap_duration\", \"duration_sector_1\", \"duration_sector_2\", \"duration_sector_3\",\n",
    "                \"pit_duration\", \"lap_start\", \"lap_end\", \"tyre_age_at_start\",\n",
    "                \"position\", \"gap_to_leader\", \"interval\",\n",
    "                \"air_temperature\", \"track_temperature\", \"humidity\"\n",
    "            ]\n",
    "        \n",
    "        if self.categorical_columns is None:\n",
    "            self.categorical_columns = [\n",
    "                \"compound\", \"flag\", \"category\", \"scope\"\n",
    "            ]\n",
    "        \n",
    "        if self.datetime_columns is None:\n",
    "            self.datetime_columns = [\n",
    "                \"date_start\", \"date_end\", \"date\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formula_one.constants import *\n",
    "from src.formula_one.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"Manages configuration loading from YAML files\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file_path: str = \"config/config.yaml\"):\n",
    "        self.config_file_path = Path(config_file_path)\n",
    "        self.config = read_yaml(self.config_file_path)\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        \"\"\"Get data transformation configuration\"\"\"\n",
    "        config_data = self.config.get('data_transformation', {})\n",
    "        \n",
    "        return DataTransformationConfig(\n",
    "            root_dir=Path(config_data.get('root_dir', 'artifacts/data_transformation')),\n",
    "            transformed_data_dir=Path(config_data.get('transformed_data_dir', 'artifacts/data_transformation/transformed')),\n",
    "            cleaned_data_dir=Path(config_data.get('cleaned_data_dir', 'artifacts/data_transformation/cleaned')),\n",
    "            missing_value_strategy=config_data.get('missing_value_strategy', 'impute'),\n",
    "            outlier_strategy=config_data.get('outlier_strategy', 'cap'),\n",
    "            outlier_threshold=config_data.get('outlier_threshold', 3.0),\n",
    "            create_tire_features=config_data.get('create_tire_features', True),\n",
    "            create_lap_features=config_data.get('create_lap_features', True),\n",
    "            create_weather_features=config_data.get('create_weather_features', True),\n",
    "            create_driver_features=config_data.get('create_driver_features', True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formula_one.entity.config_entity import DatabaseConfig\n",
    "from src.formula_one.components.data_ingestion import DatabaseIngestion\n",
    "\n",
    "class DataTransformation:\n",
    "    \"\"\"Handles data transformation for F1 data - Database-First Approach\"\"\"\n",
    "    \n",
    "    def __init__(self, transformation_config: DataTransformationConfig, db_config: DatabaseConfig):\n",
    "        self.config = transformation_config\n",
    "        self.db_config = db_config\n",
    "        self.logger = logger\n",
    "        self.db_ingestion = DatabaseIngestion(None, db_config, None)\n",
    "        \n",
    "        # Initialize transformers\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.imputers = {}\n",
    "        \n",
    "        # Store transformed data\n",
    "        self.transformed_data = {}\n",
    "        self.feature_columns = []\n",
    "    \n",
    "    def transform_all_data(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Transform all tables and update database\"\"\"\n",
    "        self.logger.info(\"Starting comprehensive data transformation (Database-First)\")\n",
    "        \n",
    "        # Create transformed tables in database\n",
    "        self._create_transformed_tables()\n",
    "\n",
    "        self._debug_table_structure('stints')\n",
    "        \n",
    "        # Transform and update each table\n",
    "        for table in self.config.tables_to_transform:\n",
    "            self.logger.info(f\"Transforming table: {table}\")\n",
    "            try:\n",
    "                df = self._load_table_data(table)\n",
    "                if df is not None and not df.empty:\n",
    "                    transformed_df = self._transform_table(df, table)\n",
    "                    self._update_database_table(table, transformed_df)\n",
    "                    self.logger.info(f\"Successfully transformed and updated {table}\")\n",
    "                else:\n",
    "                    self.logger.warning(f\"Table {table} is empty or could not be loaded\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error transforming table {table}: {str(e)}\")\n",
    "                # Continue with other tables instead of stopping\n",
    "                continue\n",
    "        \n",
    "        # Load all transformed data for return\n",
    "        self.transformed_data = self._load_all_transformed_data()\n",
    "        \n",
    "        return self.transformed_data\n",
    "    \n",
    "    def _debug_table_structure(self, table_name: str):\n",
    "        \"\"\"Debug table structure to understand what columns exist\"\"\"\n",
    "        conn = self.db_ingestion.connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT column_name, data_type, is_nullable \n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{table_name}'\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\")\n",
    "            columns = cursor.fetchall()\n",
    "            \n",
    "            self.logger.info(f\"Table structure for {table_name}:\")\n",
    "            for col in columns:\n",
    "                self.logger.info(f\"  {col[0]}: {col[1]} (nullable: {col[2]})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting table structure for {table_name}: {e}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def _create_transformed_tables(self):\n",
    "        \"\"\"Create transformed tables in database\"\"\"\n",
    "        conn = self.db_ingestion.connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            # Create transformed tables for each original table\n",
    "            tables_config = {\n",
    "                'laps': [\n",
    "                    \"lap_time_std FLOAT\",\n",
    "                    \"lap_time_mean FLOAT\", \n",
    "                    \"lap_time_deviation FLOAT\",\n",
    "                    \"total_sector_time FLOAT\",\n",
    "                    \"sector_consistency FLOAT\",\n",
    "                    \"had_incident BOOLEAN\",\n",
    "                    \"safety_car_lap BOOLEAN\",\n",
    "                    \"is_outlier BOOLEAN\",\n",
    "                ],\n",
    "                'pit_stops': [\n",
    "                    \"pit_stop_count INTEGER\",\n",
    "                    \"pit_stop_timing INTEGER\",\n",
    "                    \"normal_pit_stop BOOLEAN\",\n",
    "                    \"long_pit_stop BOOLEAN\", \n",
    "                    \"penalty_pit_stop BOOLEAN\",\n",
    "                    \"is_outlier BOOLEAN\",\n",
    "                ],\n",
    "                'stints': [\n",
    "                    \"stint_duration INTEGER\",\n",
    "                    \"tire_age_progression INTEGER\",\n",
    "                    \"is_outlier BOOLEAN\",\n",
    "                ],\n",
    "                'positions': [\n",
    "                    \"position_change INTEGER\",\n",
    "                    \"position_std FLOAT\",\n",
    "                    \"is_leader BOOLEAN\",\n",
    "                    \"position_improved BOOLEAN\",\n",
    "                    \"position_declined BOOLEAN\",\n",
    "                    \"is_outlier BOOLEAN\",\n",
    "                ],\n",
    "                'intervals': [\n",
    "                    \"is_leader BOOLEAN\",\n",
    "                    \"is_lapped BOOLEAN\",\n",
    "                    \"is_outlier BOOLEAN\"\n",
    "                ],\n",
    "                'weather': [\n",
    "                    \"temperature_delta FLOAT\",\n",
    "                    \"weather_severity FLOAT\",\n",
    "                    \"extreme_weather BOOLEAN\",\n",
    "                ],\n",
    "                'drivers': [\n",
    "                    \"team_name_encoded INTEGER\",\n",
    "                ],\n",
    "                'sessions': [\n",
    "                    \"session_type_encoded INTEGER\",\n",
    "                ],\n",
    "            }\n",
    "            \n",
    "            for table_name, new_columns in tables_config.items():\n",
    "                # Create transformed table\n",
    "                cursor.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS {table_name}_transformed AS \n",
    "                    SELECT * FROM {table_name}\n",
    "                \"\"\")\n",
    "                \n",
    "                # Add new columns for transformed features\n",
    "                for column_def in new_columns:\n",
    "                    try:\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name}_transformed ADD COLUMN IF NOT EXISTS {column_def}\")\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"Could not add column {column_def} to {table_name}_transformed: {e}\")\n",
    "            \n",
    "            conn.commit()\n",
    "            self.logger.info(\"Created transformed tables in database\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            self.logger.error(f\"Error creating transformed tables: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def _load_table_data(self, table_name: str) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Load data from database table\"\"\"\n",
    "        conn = self.db_ingestion.connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "            if data:\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                return df\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading table {table_name}: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def _transform_table(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Transform a specific table\"\"\"\n",
    "        self.logger.info(f\"Transforming {table_name} with {len(df)} rows\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Handle missing values\n",
    "            df = self._handle_missing_values(df, table_name)\n",
    "            \n",
    "            # Step 2: Fix data types\n",
    "            df = self._fix_data_types(df, table_name)\n",
    "            \n",
    "            # Step 3: Handle outliers\n",
    "            df = self._handle_outliers(df, table_name)\n",
    "            \n",
    "            # Step 4: Encode categorical variables\n",
    "            df = self._encode_categorical_variables(df, table_name)\n",
    "            \n",
    "            # Step 5: Create table-specific features\n",
    "            df = self._create_table_specific_features(df, table_name)\n",
    "            \n",
    "            # Debug the final result\n",
    "            self._debug_table_data(df, table_name)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in _transform_table for {table_name}: {e}\")\n",
    "            # Return the original dataframe with basic transformations\n",
    "            # Only add is_outlier for tables that have it in schema\n",
    "            tables_with_outliers = ['laps', 'pit_stops', 'stints', 'positions', 'intervals']\n",
    "            if table_name in tables_with_outliers:\n",
    "                df['is_outlier'] = False\n",
    "                df['outlier_type'] = 'normal'\n",
    "            return df\n",
    "    \n",
    "    def _handle_missing_values(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Handle missing values based on strategy\"\"\"\n",
    "        self.logger.info(f\"Handling missing values in {table_name}\")\n",
    "        \n",
    "        try:\n",
    "            if self.config.missing_value_strategy == \"impute\":\n",
    "                # Use different strategies for different column types\n",
    "                for column in df.columns:\n",
    "                    if column in self.config.numeric_columns and df[column].dtype in ['float64', 'int64']:\n",
    "                        # Use median for numeric columns\n",
    "                        try:\n",
    "                            imputer = SimpleImputer(strategy='median')\n",
    "                            df[column] = imputer.fit_transform(df[[column]])\n",
    "                            self.imputers[f\"{table_name}_{column}\"] = imputer\n",
    "                        except Exception as e:\n",
    "                            self.logger.warning(f\"Could not impute {column} in {table_name}: {e}\")\n",
    "                            # Fallback to forward fill then backward fill\n",
    "                            df[column] = df[column].ffill().bfill().fillna(0)\n",
    "                            \n",
    "                    elif column in self.config.categorical_columns:\n",
    "                        # Use most frequent for categorical columns\n",
    "                        try:\n",
    "                            imputer = SimpleImputer(strategy='most_frequent')\n",
    "                            df[column] = imputer.fit_transform(df[[column]])\n",
    "                            self.imputers[f\"{table_name}_{column}\"] = imputer\n",
    "                        except Exception as e:\n",
    "                            self.logger.warning(f\"Could not impute {column} in {table_name}: {e}\")\n",
    "                            # Fallback to 'Unknown'\n",
    "                            df[column] = df[column].fillna('Unknown')\n",
    "                            \n",
    "                    elif column in self.config.datetime_columns:\n",
    "                        # Forward fill for datetime columns\n",
    "                        df[column] = df[column].ffill().bfill()\n",
    "\n",
    "            \n",
    "            elif self.config.missing_value_strategy == \"drop\":\n",
    "                df = df.dropna()\n",
    "            \n",
    "            elif self.config.missing_value_strategy == \"interpolate\":\n",
    "                # Interpolate numeric columns\n",
    "                try:\n",
    "                    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                    df[numeric_cols] = df[numeric_cols].interpolate(method='linear')\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Could not interpolate numeric columns in {table_name}: {e}\")\n",
    "                    # Fallback to forward fill\n",
    "                    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                    df[numeric_cols] = df[numeric_cols].ffill().bfill().fillna(0)\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in _handle_missing_values for {table_name}: {e}\")\n",
    "            # Return dataframe with basic missing value handling\n",
    "            for column in df.columns:\n",
    "                if df[column].dtype in ['float64', 'int64']:\n",
    "                    df[column] = df[column].fillna(0)\n",
    "                elif df[column].dtype == 'object':\n",
    "                    df[column] = df[column].fillna('Unknown')\n",
    "            return df\n",
    "    \n",
    "    def _fix_data_types(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Fix data types for each column\"\"\"\n",
    "        self.logger.info(f\"Fixing data types in {table_name}\")\n",
    "        \n",
    "        for column in df.columns:\n",
    "            if column in self.config.numeric_columns:\n",
    "                try:\n",
    "                    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "                except:\n",
    "                    self.logger.warning(f\"Could not convert {column} to numeric in {table_name}\")\n",
    "            \n",
    "            elif column in self.config.datetime_columns:\n",
    "                try:\n",
    "                    df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "                except:\n",
    "                    self.logger.warning(f\"Could not convert {column} to datetime in {table_name}\")\n",
    "            \n",
    "            elif column in self.config.categorical_columns:\n",
    "                df[column] = df[column].astype('category')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _handle_outliers(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Handle outliers with F1-specific context\"\"\"\n",
    "        if self.config.outlier_strategy == \"ignore\":\n",
    "            return df\n",
    "        \n",
    "        self.logger.info(f\"Handling outliers in {table_name} with F1 context\")\n",
    "\n",
    "        tables_with_outliers = ['laps', 'pit_stops', 'stints', 'positions', 'intervals']\n",
    "        \n",
    "        # Detect F1-specific outliers\n",
    "        df = self._detect_f1_outliers(df, table_name)\n",
    "        \n",
    "        # Handle based on strategy\n",
    "        if self.config.outlier_strategy == \"context_aware\":\n",
    "            # Flag outliers but keep all data\n",
    "            df = self._flag_outliers_context_aware(df, table_name)\n",
    "            \n",
    "        elif self.config.outlier_strategy == \"remove_system_errors\":\n",
    "            # Only remove obvious system errors\n",
    "            df = self._remove_only_system_errors(df, table_name)\n",
    "            \n",
    "        elif self.config.outlier_strategy == \"cap\":\n",
    "            # Cap outliers to reasonable bounds\n",
    "            df = self._cap_outliers_f1_context(df, table_name)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _detect_f1_outliers(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Detect outliers with F1-specific rules\"\"\"\n",
    "        \n",
    "        if table_name == \"laps\":\n",
    "            # Lap time outliers\n",
    "            df['is_outlier'] = (\n",
    "                (df['lap_duration'] < 0) | \n",
    "                (df['lap_duration'] > 9999) |\n",
    "                (df['lap_duration'] == 0) |\n",
    "                (df['lap_duration'] > 300)\n",
    "            )\n",
    "            \n",
    "        elif table_name == \"pit_stops\":\n",
    "            # Pit stop outliers\n",
    "            df['is_outlier'] = (\n",
    "                (df['pit_duration'] < 0) |\n",
    "                (df['pit_duration'] > 1000) | \n",
    "                (df['pit_duration'] == 0)\n",
    "            )\n",
    "            \n",
    "        elif table_name == \"positions\":\n",
    "            # Position outliers\n",
    "            df['is_outlier'] = (\n",
    "                (df['position'] > 50) |\n",
    "                (df['position'] < -1)\n",
    "            )\n",
    "            \n",
    "        elif table_name == \"intervals\":\n",
    "            # Interval outliers\n",
    "            df['is_outlier'] = (\n",
    "                (df['gap_to_leader'] < -1000) |  # System errors\n",
    "                (df['gap_to_leader'] > 10000) |  # System errors\n",
    "                (df['interval'] < -1000) |  # System errors\n",
    "                (df['interval'] > 10000)  # System errors\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            # For other tables, use standard outlier detection\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "            df['is_outlier'] = False\n",
    "            \n",
    "            for column in numeric_cols:\n",
    "                if column in ['id', 'created_at', 'is_outlier']:  # Skip metadata columns\n",
    "                    continue\n",
    "                    \n",
    "                Q1 = df[column].quantile(0.25)\n",
    "                Q3 = df[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                column_outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "                df['is_outlier'] = df['is_outlier'] | column_outliers\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _flag_outliers_context_aware(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Flag outliers but keep all data - create features from outliers\"\"\"\n",
    "        \n",
    "        if 'is_outlier' not in df.columns:\n",
    "            df['is_outlier'] = False\n",
    "        \n",
    "        # Classify outlier types\n",
    "        df['outlier_type'] = self._classify_outlier_type(df, table_name)\n",
    "        \n",
    "        # Create features from outliers\n",
    "        if table_name == \"laps\":\n",
    "            df['had_incident'] = ((df['lap_duration'] > 120) & (df['lap_duration'] <= 300)).astype(bool)\n",
    "            df['safety_car_lap'] = ((df['lap_duration'] > 90) & (df['lap_duration'] <= 120)).astype(bool)\n",
    "            \n",
    "        elif table_name == \"pit_stops\":\n",
    "            df['normal_pit_stop'] = ((df['pit_duration'] >= 0.5) & (df['pit_duration'] <= 5)).astype(bool)\n",
    "            df['long_pit_stop'] = ((df['pit_duration'] > 5) & (df['pit_duration'] <= 60)).astype(bool)\n",
    "            df['penalty_pit_stop'] = ((df['pit_duration'] > 60) & (df['pit_duration'] <= 300)).astype(bool)\n",
    "            \n",
    "        elif table_name == \"positions\":\n",
    "            df['is_leader'] = (df['position'] == 0).astype(bool)\n",
    "            df['is_retired'] = (df['position'] == -1).astype(bool)\n",
    "            df['is_lapped'] = (df['position'] > 20).astype(bool)\n",
    "            \n",
    "        elif table_name == \"intervals\":\n",
    "            df['is_leader'] = (df['gap_to_leader'] == 0).astype(bool)\n",
    "            df['is_lapped'] = ((df['gap_to_leader'] == -999) | (df['interval'] == -999)).astype(bool)\n",
    "\n",
    "        elif table_name == \"weather\":\n",
    "            df['extreme_weather'] = (\n",
    "                ((df['air_temperature'] < -20) | (df['air_temperature'] > 50)) |\n",
    "                ((df['track_temperature'] < -10) | (df['track_temperature'] > 80)) |\n",
    "                (df['humidity'] > 90)\n",
    "            ).astype(bool)\n",
    "\n",
    "        self.logger.info(f\"Flagged {df['is_outlier'].sum()} outliers in {table_name}\")\n",
    "        return df\n",
    "    \n",
    "    def _remove_only_system_errors(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Only remove obvious system errors, keep all race events\"\"\"\n",
    "        \n",
    "        if table_name == \"laps\":\n",
    "            # Remove only system errors\n",
    "            df = df[df['lap_duration'] > 0]  # Remove negative times\n",
    "            df = df[df['lap_duration'] < 9999]  # Remove system errors\n",
    "            self.logger.info(f\"Removed system errors from {table_name}\")\n",
    "            \n",
    "        elif table_name == \"pit_stops\":\n",
    "            # Remove only system errors\n",
    "            df = df[df['pit_duration'] >= 0]  # Remove negative durations\n",
    "            df = df[df['pit_duration'] < 1000]  # Remove system errors\n",
    "            self.logger.info(f\"Removed system errors from {table_name}\")\n",
    "            \n",
    "        elif table_name == \"positions\":\n",
    "            # Remove only system errors\n",
    "            df = df[df['position'] <= 50]  # Remove impossible positions\n",
    "            df = df[df['position'] >= -1]  # Remove invalid negatives\n",
    "            self.logger.info(f\"Removed system errors from {table_name}\")\n",
    "            \n",
    "        elif table_name == \"intervals\":\n",
    "            # Remove only system errors\n",
    "            df = df[df['gap_to_leader'] >= -1000]  # Remove system errors\n",
    "            df = df[df['gap_to_leader'] <= 10000]  # Remove system errors\n",
    "            df = df[df['interval'] >= -1000]  # Remove system errors\n",
    "            df = df[df['interval'] <= 10000]  # Remove system errors\n",
    "            self.logger.info(f\"Removed system errors from {table_name}\")\n",
    "            \n",
    "        elif table_name == \"weather\":\n",
    "            # Remove only system errors\n",
    "            df = df[df['air_temperature'] >= -50]  # Remove impossible cold\n",
    "            df = df[df['air_temperature'] <= 100]  # Remove impossible hot\n",
    "            df = df[df['humidity'] >= 0]  # Remove impossible humidity\n",
    "            df = df[df['humidity'] <= 100]  # Remove impossible humidity\n",
    "            self.logger.info(f\"Removed system errors from {table_name}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _cap_outliers_f1_context(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Cap outliers to reasonable F1 bounds\"\"\"\n",
    "        \n",
    "        if table_name == \"laps\":\n",
    "            # Cap lap times to reasonable bounds\n",
    "            df['lap_duration'] = df['lap_duration'].clip(lower=0, upper=300)\n",
    "            \n",
    "        elif table_name == \"pit_stops\":\n",
    "            # Cap pit durations to reasonable bounds\n",
    "            df['pit_duration'] = df['pit_duration'].clip(lower=0, upper=300)\n",
    "            \n",
    "        elif table_name == \"positions\":\n",
    "            # Cap positions to reasonable bounds\n",
    "            df['position'] = df['position'].clip(lower=-1, upper=50)\n",
    "            \n",
    "        elif table_name == \"intervals\":\n",
    "            # Cap intervals to reasonable bounds\n",
    "            df['gap_to_leader'] = df['gap_to_leader'].clip(lower=-999, upper=999)\n",
    "            df['interval'] = df['interval'].clip(lower=-999, upper=999)\n",
    "            \n",
    "        elif table_name == \"weather\":\n",
    "            # Cap weather to reasonable bounds\n",
    "            df['air_temperature'] = df['air_temperature'].clip(lower=-50, upper=100)\n",
    "            df['track_temperature'] = df['track_temperature'].clip(lower=-50, upper=150)\n",
    "            df['humidity'] = df['humidity'].clip(lower=0, upper=100)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _classify_outlier_type(self, df: pd.DataFrame, table_name: str) -> pd.Series:\n",
    "        \"\"\"Classify outliers by type\"\"\"\n",
    "        \n",
    "        outlier_types = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if not row.get('is_outlier', False):\n",
    "                outlier_types.append('normal')\n",
    "                continue\n",
    "                \n",
    "            if table_name == \"laps\":\n",
    "                if row['lap_duration'] < 0 or row['lap_duration'] > 9999:\n",
    "                    pass\n",
    "                elif row['lap_duration'] > 120:\n",
    "                    outlier_types.append('incident_safety_car')\n",
    "                elif row['lap_duration'] < 15:\n",
    "                    outlier_types.append('qualifying_slipstream')\n",
    "                else:\n",
    "                    outlier_types.append('unknown')\n",
    "                    \n",
    "            elif table_name == \"pit_stops\":\n",
    "                if row['pit_duration'] < 0 or row['pit_duration'] > 1000:\n",
    "                    pass\n",
    "                elif row['pit_duration'] > 60:\n",
    "                    outlier_types.append('penalty_repair')\n",
    "                elif row['pit_duration'] < 0.5:\n",
    "                    outlier_types.append('very_fast_stop')\n",
    "                else:\n",
    "                    outlier_types.append('unknown')\n",
    "                    \n",
    "            elif table_name == \"positions\":\n",
    "                if row['position'] > 50 or row['position'] < -1:\n",
    "                    pass\n",
    "                elif row['position'] == -1:\n",
    "                    outlier_types.append('retired')\n",
    "                elif row['position'] > 20:\n",
    "                    outlier_types.append('lapped')\n",
    "                else:\n",
    "                    outlier_types.append('unknown')\n",
    "                    \n",
    "            else:\n",
    "                outlier_types.append('unknown')\n",
    "        \n",
    "        return pd.Series(outlier_types)\n",
    "    \n",
    "    def _encode_categorical_variables(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Encode categorical variables\"\"\"\n",
    "        self.logger.info(f\"Encoding categorical variables in {table_name}\")\n",
    "        \n",
    "        # Define which columns to encode for each table\n",
    "        encoding_config = {\n",
    "            'sessions': ['session_type'],\n",
    "            'drivers': ['team_name'],\n",
    "        }\n",
    "        \n",
    "        if table_name in encoding_config:\n",
    "            for column in encoding_config[table_name]:\n",
    "                if column in df.columns:\n",
    "                    # Handle missing values first - use a different approach for categorical\n",
    "                    if df[column].dtype.name == 'category':\n",
    "                        # If it's already categorical, add 'Unknown' to categories first\n",
    "                        current_categories = df[column].cat.categories.tolist()\n",
    "                        if 'Unknown' not in current_categories:\n",
    "                            df[column] = df[column].cat.add_categories(['Unknown'])\n",
    "                        df[column] = df[column].fillna('Unknown')\n",
    "                    else:\n",
    "                        # Convert to string and fill missing values\n",
    "                        df[column] = df[column].astype(str).fillna('Unknown')\n",
    "                    \n",
    "                    # Create label encoder\n",
    "                    le = LabelEncoder()\n",
    "                    try:\n",
    "                        # Fit and transform\n",
    "                        encoded_values = le.fit_transform(df[column].astype(str))\n",
    "                        df[f\"{column}_encoded\"] = encoded_values\n",
    "                        self.label_encoders[f\"{table_name}_{column}\"] = le\n",
    "                        \n",
    "                        self.logger.info(f\"Encoded {column} in {table_name} with {len(le.classes_)} unique values\")\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"Could not encode {column} in {table_name}: {e}\")\n",
    "                        df[f\"{column}_encoded\"] = 0  # Default value\n",
    "                else:\n",
    "                    self.logger.warning(f\"Column {column} not found in {table_name}\")\n",
    "                    df[f\"{column}_encoded\"] = 0  # Default value\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _create_table_specific_features(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        \"\"\"Create table-specific features\"\"\"\n",
    "        try:\n",
    "            if table_name == \"laps\":\n",
    "                df = self._create_lap_features(df)\n",
    "            elif table_name == \"stints\":\n",
    "                df = self._create_stint_features(df)\n",
    "            elif table_name == \"pit_stops\":\n",
    "                df = self._create_pit_stop_features(df)\n",
    "            elif table_name == \"positions\":\n",
    "                df = self._create_position_features(df)\n",
    "            elif table_name == \"intervals\":\n",
    "                df = self._create_interval_features(df)\n",
    "            elif table_name == \"weather\":\n",
    "                df = self._create_weather_features(df)\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in _create_table_specific_features for {table_name}: {e}\")\n",
    "            return df\n",
    "    \n",
    "    def _create_lap_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create lap-specific features\"\"\"\n",
    "        # Lap time consistency\n",
    "        df['lap_time_std'] = df.groupby('driver_number')['lap_duration'].transform('std')\n",
    "        df['lap_time_mean'] = df.groupby('driver_number')['lap_duration'].transform('mean')\n",
    "        df['lap_time_deviation'] = df['lap_duration'] - df['lap_time_mean']\n",
    "        \n",
    "        # Sector analysis\n",
    "        df['total_sector_time'] = df['duration_sector_1'] + df['duration_sector_2'] + df['duration_sector_3']\n",
    "        df['sector_consistency'] = df[['duration_sector_1', 'duration_sector_2', 'duration_sector_3']].std(axis=1)\n",
    "        \n",
    "        # Boolean features for laps\n",
    "        df['had_incident'] = ((df['lap_duration'] > 120) & (df['lap_duration'] <= 300)).astype(bool)\n",
    "        df['safety_car_lap'] = ((df['lap_duration'] > 90) & (df['lap_duration'] <= 120)).astype(bool)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def _create_stint_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create stint-specific features\"\"\"\n",
    "        try:\n",
    "            # Ensure we have the required columns\n",
    "            required_cols = ['lap_start', 'lap_end', 'tyre_age_at_start', 'session_key', 'driver_number']\n",
    "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                self.logger.warning(f\"Missing columns in stints: {missing_cols}\")\n",
    "                # Add default values for missing columns\n",
    "                for col in missing_cols:\n",
    "                    df[col] = 0\n",
    "            \n",
    "            # Stint duration - handle missing values and invalid data\n",
    "            df['stint_duration'] = df['lap_end'] - df['lap_start']\n",
    "            # Handle cases where lap_end < lap_start (invalid data)\n",
    "            df['stint_duration'] = df['stint_duration'].clip(lower=0, upper=100)\n",
    "            df['stint_duration'] = df['stint_duration'].fillna(0)\n",
    "            \n",
    "            # Tire age progression - handle missing values\n",
    "            try:\n",
    "                df['tire_age_progression'] = df.groupby(['session_key', 'driver_number'])['tyre_age_at_start'].diff()\n",
    "                df['tire_age_progression'] = df['tire_age_progression'].fillna(0).clip(lower=0, upper=50)\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Could not calculate tire_age_progression: {e}\")\n",
    "                df['tire_age_progression'] = 0\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in _create_stint_features: {e}\")\n",
    "            # Return dataframe with default values\n",
    "            df['stint_duration'] = 0\n",
    "            df['tire_age_progression'] = 0\n",
    "            return df\n",
    "    \n",
    "    def _create_pit_stop_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create pit stop-specific features with ALL features included\"\"\"\n",
    "\n",
    "        df['pit_stop_count'] = df.groupby(['session_key', 'driver_number']).cumcount() + 1\n",
    "        df['pit_stop_count'] = df['pit_stop_count'].clip(upper=20)  # Cap at 20 pit stops (more reasonable)\n",
    "        \n",
    "        df['pit_stop_timing'] = df.groupby(['session_key', 'driver_number'])['lap_number'].diff()\n",
    "        df['pit_stop_timing'] = df['pit_stop_timing'].clip(lower=0, upper=50)  # Cap at 50 laps\n",
    "\n",
    "        df['normal_pit_stop'] = (df['pit_duration'] >= 0.5) & (df['pit_duration'] <= 5)\n",
    "        df['long_pit_stop'] = (df['pit_duration'] > 5) & (df['pit_duration'] <= 60)\n",
    "        df['penalty_pit_stop'] = (df['pit_duration'] > 60) & (df['pit_duration'] <= 300)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_position_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create position-specific features with ALL features included\"\"\"\n",
    "\n",
    "        df['position_change'] = df.groupby(['session_key', 'driver_number'])['position'].diff()\n",
    "        df['position_change'] = df['position_change'].clip(lower=-20, upper=20) \n",
    "        \n",
    "        df['position_std'] = df.groupby(['session_key', 'driver_number'])['position'].transform('std')\n",
    "        df['position_std'] = df['position_std'].clip(upper=20) \n",
    "        \n",
    "        df['is_leader'] = (df['position'] == 1).astype(bool) \n",
    "\n",
    "        # Position improvement/decline\n",
    "        df['position_improved'] = (df['position_change'] < 0).astype(bool)\n",
    "        df['position_declined'] = (df['position_change'] > 0).astype(bool)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_interval_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create interval-specific features with ALL features included\"\"\"\n",
    "        # Boolean features (these should be created here, not in outlier handling)\n",
    "        df['is_leader'] = df['gap_to_leader'] == 0\n",
    "        df['is_lapped'] = (df['gap_to_leader'] == -999) | (df['interval'] == -999)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _create_weather_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create weather-specific features\"\"\"\n",
    "        # Weather impact features\n",
    "        df['temperature_delta'] = df['track_temperature'] - df['air_temperature']\n",
    "        df['weather_severity'] = df['humidity'] * df['rainfall'].astype(int)\n",
    "        \n",
    "        # Boolean features for weather\n",
    "        df['extreme_weather'] = (\n",
    "            ((df['air_temperature'] < -20) | (df['air_temperature'] > 50)) |\n",
    "            ((df['track_temperature'] < -10) | (df['track_temperature'] > 80)) |\n",
    "            (df['humidity'] > 90)\n",
    "        ).astype(bool)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _update_database_table(self, table_name: str, df: pd.DataFrame):\n",
    "        \"\"\"Update transformed table in database\"\"\"\n",
    "        conn = self.db_ingestion.connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            # First, get the actual columns that exist in the database table\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT column_name \n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{table_name}_transformed'\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\")\n",
    "            db_columns = [row[0] for row in cursor.fetchall()]\n",
    "            \n",
    "            # Filter DataFrame to only include columns that exist in the database\n",
    "            df_clean = df[db_columns].copy()\n",
    "            \n",
    "            # Convert numeric columns to appropriate types\n",
    "            for col in df_clean.columns:\n",
    "                if 'count' in col or 'timing' in col or 'duration' in col or 'change' in col or 'progression' in col:\n",
    "                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype('int32')\n",
    "                elif 'std' in col or 'mean' in col or 'deviation' in col or 'consistency' in col:\n",
    "                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0.0).astype('float32')\n",
    "                elif col in ['is_outlier', 'had_incident', 'safety_car_lap', \n",
    "                            'normal_pit_stop', 'long_pit_stop', 'penalty_pit_stop', 'is_leader', 'is_retired', \n",
    "                            'is_lapped', 'extreme_weather']:\n",
    "                    df_clean[col] = df_clean[col].fillna(False).astype('bool')\n",
    "                elif col.endswith('_encoded'):\n",
    "                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype('int32')\n",
    "                elif col == 'outlier_type':\n",
    "                    df_clean[col] = df_clean[col].fillna('normal')\n",
    "            \n",
    "            # Clear existing data\n",
    "            cursor.execute(f\"DELETE FROM {table_name}_transformed\")\n",
    "            \n",
    "            # Insert transformed data\n",
    "            for _, row in df_clean.iterrows():\n",
    "                placeholders = ', '.join(['%s'] * len(row))\n",
    "                columns = ', '.join(row.index)\n",
    "                query = f\"INSERT INTO {table_name}_transformed ({columns}) VALUES ({placeholders})\"\n",
    "                cursor.execute(query, tuple(row.values))\n",
    "            \n",
    "            conn.commit()\n",
    "            self.logger.info(f\"Updated {table_name}_transformed with {len(df)} rows\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            self.logger.error(f\"Error updating {table_name}_transformed: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def _load_all_transformed_data(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Load all transformed data from database\"\"\"\n",
    "        transformed_data = {}\n",
    "        \n",
    "        for table in self.config.tables_to_transform:\n",
    "            df = self._load_table_data(f\"{table}_transformed\")\n",
    "            if df is not None:\n",
    "                transformed_data[table] = df\n",
    "        \n",
    "        return transformed_data\n",
    "    \n",
    "    def get_feature_columns(self) -> List[str]:\n",
    "        \"\"\"Get list of feature columns for ML\"\"\"\n",
    "        feature_cols = []\n",
    "        for df in self.transformed_data.values():\n",
    "            # Exclude metadata columns\n",
    "            exclude_cols = ['id', 'created_at', 'meeting_key', 'session_key']\n",
    "            feature_cols.extend([col for col in df.columns if col not in exclude_cols])\n",
    "        return list(set(feature_cols))\n",
    "    \n",
    "    def _debug_table_data(self, df: pd.DataFrame, table_name: str):\n",
    "        \"\"\"Debug method to see what's happening with the data\"\"\"\n",
    "        self.logger.info(f\"DEBUG {table_name}:\")\n",
    "        self.logger.info(f\"  Shape: {df.shape}\")\n",
    "        self.logger.info(f\"  Columns: {list(df.columns)}\")\n",
    "        self.logger.info(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
    "        \n",
    "        # Check for encoded columns\n",
    "        encoded_cols = [col for col in df.columns if col.endswith('_encoded')]\n",
    "        if encoded_cols:\n",
    "            self.logger.info(f\"  Encoded columns: {encoded_cols}\")\n",
    "            for col in encoded_cols:\n",
    "                self.logger.info(f\"    {col}: {df[col].value_counts().to_dict()}\")\n",
    "        \n",
    "        # Check for boolean columns\n",
    "        tables_with_outliers = ['laps', 'pit_stops', 'stints', 'positions', 'intervals']\n",
    "        if table_name in tables_with_outliers:\n",
    "            boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "            if boolean_cols:\n",
    "                self.logger.info(f\"  Boolean columns: {boolean_cols}\")\n",
    "                for col in boolean_cols:\n",
    "                    value_counts = df[col].value_counts().to_dict()\n",
    "                    self.logger.info(f\"    {col}: {value_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 19:29:12,766: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "Dropped sessions_transformed\n",
      "Dropped drivers_transformed\n",
      "Dropped laps_transformed\n",
      "Dropped pit_stops_transformed\n",
      "Dropped stints_transformed\n",
      "Dropped positions_transformed\n",
      "Dropped intervals_transformed\n",
      "Dropped weather_transformed\n",
      "All transformed tables dropped successfully!\n"
     ]
    }
   ],
   "source": [
    "# ADD THIS CELL BEFORE RUNNING TRANSFORMATION\n",
    "# Force drop all transformed tables to recreate with correct column types\n",
    "\n",
    "from src.formula_one.entity.config_entity import DatabaseConfig\n",
    "from src.formula_one.components.data_ingestion import DatabaseIngestion\n",
    "\n",
    "# Create database connection\n",
    "db_config = DatabaseConfig()\n",
    "db_ingestion = DatabaseIngestion(None, db_config, None)\n",
    "conn = db_ingestion.connect_to_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Drop all transformed tables\n",
    "    tables_to_drop = [\n",
    "        \"sessions_transformed\", \"drivers_transformed\",\n",
    "        \"laps_transformed\", \"pit_stops_transformed\", \"stints_transformed\", \n",
    "        \"positions_transformed\", \"intervals_transformed\", \"weather_transformed\"\n",
    "    ]\n",
    "    \n",
    "    for table in tables_to_drop:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table} CASCADE\")\n",
    "        print(f\"Dropped {table}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"All transformed tables dropped successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error dropping tables: {e}\")\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 19:29:12,776: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-03 19:29:12,777: INFO: 946721898: Starting comprehensive data transformation (Database-First)]\n",
      "[2025-07-03 19:29:12,781: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,311: INFO: 946721898: Created transformed tables in database]\n",
      "[2025-07-03 19:29:13,315: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,318: INFO: 946721898: Table structure for stints:]\n",
      "[2025-07-03 19:29:13,318: INFO: 946721898:   id: integer (nullable: NO)]\n",
      "[2025-07-03 19:29:13,319: INFO: 946721898:   session_key: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,319: INFO: 946721898:   meeting_key: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,319: INFO: 946721898:   driver_number: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,320: INFO: 946721898:   compound: character varying (nullable: YES)]\n",
      "[2025-07-03 19:29:13,320: INFO: 946721898:   lap_start: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,320: INFO: 946721898:   lap_end: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,321: INFO: 946721898:   tyre_age_at_start: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,321: INFO: 946721898:   created_at: timestamp without time zone (nullable: YES)]\n",
      "[2025-07-03 19:29:13,324: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,327: INFO: 946721898: Table structure for race_control:]\n",
      "[2025-07-03 19:29:13,327: INFO: 946721898:   id: integer (nullable: NO)]\n",
      "[2025-07-03 19:29:13,328: INFO: 946721898:   session_key: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,328: INFO: 946721898:   meeting_key: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,328: INFO: 946721898:   driver_number: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,328: INFO: 946721898:   category: character varying (nullable: YES)]\n",
      "[2025-07-03 19:29:13,329: INFO: 946721898:   flag: character varying (nullable: YES)]\n",
      "[2025-07-03 19:29:13,329: INFO: 946721898:   lap_number: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,329: INFO: 946721898:   message: text (nullable: YES)]\n",
      "[2025-07-03 19:29:13,329: INFO: 946721898:   scope: character varying (nullable: YES)]\n",
      "[2025-07-03 19:29:13,330: INFO: 946721898:   sector: integer (nullable: YES)]\n",
      "[2025-07-03 19:29:13,330: INFO: 946721898:   date: timestamp without time zone (nullable: YES)]\n",
      "[2025-07-03 19:29:13,330: INFO: 946721898:   created_at: timestamp without time zone (nullable: YES)]\n",
      "[2025-07-03 19:29:13,331: INFO: 946721898: Transforming table: sessions]\n",
      "[2025-07-03 19:29:13,333: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,336: INFO: 946721898: Transforming sessions with 53 rows]\n",
      "[2025-07-03 19:29:13,336: INFO: 946721898: Handling missing values in sessions]\n",
      "[2025-07-03 19:29:13,340: INFO: 946721898: Fixing data types in sessions]\n",
      "[2025-07-03 19:29:13,341: INFO: 946721898: Handling outliers in sessions with F1 context]\n",
      "[2025-07-03 19:29:13,343: INFO: 946721898: Encoding categorical variables in sessions]\n",
      "[2025-07-03 19:29:13,345: INFO: 946721898: Encoded session_type in sessions with 3 unique values]\n",
      "[2025-07-03 19:29:13,345: INFO: 946721898: DEBUG sessions:]\n",
      "[2025-07-03 19:29:13,345: INFO: 946721898:   Shape: (53, 9)]\n",
      "[2025-07-03 19:29:13,345: INFO: 946721898:   Columns: ['session_key', 'meeting_key', 'session_name', 'session_type', 'date_start', 'date_end', 'created_at', 'is_outlier', 'session_type_encoded']]\n",
      "[2025-07-03 19:29:13,346: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:13,346: INFO: 946721898:   Encoded columns: ['session_type_encoded']]\n",
      "[2025-07-03 19:29:13,346: INFO: 946721898:     session_type_encoded: {0: 29, 2: 13, 1: 11}]\n",
      "[2025-07-03 19:29:13,349: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,363: INFO: 946721898: Updated sessions_transformed with 53 rows]\n",
      "[2025-07-03 19:29:13,364: INFO: 946721898: Successfully transformed and updated sessions]\n",
      "[2025-07-03 19:29:13,364: INFO: 946721898: Transforming table: drivers]\n",
      "[2025-07-03 19:29:13,367: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,370: INFO: 946721898: Transforming drivers with 1059 rows]\n",
      "[2025-07-03 19:29:13,370: INFO: 946721898: Handling missing values in drivers]\n",
      "[2025-07-03 19:29:13,370: INFO: 946721898: Fixing data types in drivers]\n",
      "[2025-07-03 19:29:13,370: INFO: 946721898: Handling outliers in drivers with F1 context]\n",
      "[2025-07-03 19:29:13,373: INFO: 946721898: Encoding categorical variables in drivers]\n",
      "[2025-07-03 19:29:13,374: INFO: 946721898: Encoded team_name in drivers with 10 unique values]\n",
      "[2025-07-03 19:29:13,374: INFO: 946721898: DEBUG drivers:]\n",
      "[2025-07-03 19:29:13,374: INFO: 946721898:   Shape: (1059, 9)]\n",
      "[2025-07-03 19:29:13,374: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'full_name', 'team_name', 'created_at', 'is_outlier', 'team_name_encoded']]\n",
      "[2025-07-03 19:29:13,375: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:13,375: INFO: 946721898:   Encoded columns: ['team_name_encoded']]\n",
      "[2025-07-03 19:29:13,375: INFO: 946721898:     team_name_encoded: {8: 106, 5: 106, 4: 106, 7: 106, 0: 106, 6: 106, 2: 106, 9: 106, 3: 106, 1: 105}]\n",
      "[2025-07-03 19:29:13,378: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,468: INFO: 946721898: Updated drivers_transformed with 1059 rows]\n",
      "[2025-07-03 19:29:13,468: INFO: 946721898: Successfully transformed and updated drivers]\n",
      "[2025-07-03 19:29:13,468: INFO: 946721898: Transforming table: laps]\n",
      "[2025-07-03 19:29:13,471: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:13,528: INFO: 946721898: Transforming laps with 29981 rows]\n",
      "[2025-07-03 19:29:13,528: INFO: 946721898: Handling missing values in laps]\n",
      "[2025-07-03 19:29:13,540: INFO: 946721898: Fixing data types in laps]\n",
      "[2025-07-03 19:29:13,542: INFO: 946721898: Handling outliers in laps with F1 context]\n",
      "[2025-07-03 19:29:13,544: INFO: 946721898: Encoding categorical variables in laps]\n",
      "[2025-07-03 19:29:13,552: INFO: 946721898: DEBUG laps:]\n",
      "[2025-07-03 19:29:13,552: INFO: 946721898:   Shape: (29981, 19)]\n",
      "[2025-07-03 19:29:13,553: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'lap_number', 'lap_duration', 'duration_sector_1', 'duration_sector_2', 'duration_sector_3', 'is_pit_out_lap', 'created_at', 'is_outlier', 'lap_time_std', 'lap_time_mean', 'lap_time_deviation', 'total_sector_time', 'sector_consistency', 'had_incident', 'safety_car_lap']]\n",
      "[2025-07-03 19:29:13,554: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:13,554: INFO: 946721898:   Boolean columns: ['is_pit_out_lap', 'is_outlier', 'had_incident', 'safety_car_lap']]\n",
      "[2025-07-03 19:29:13,555: INFO: 946721898:     is_pit_out_lap: {False: 25675, True: 4306}]\n",
      "[2025-07-03 19:29:13,555: INFO: 946721898:     is_outlier: {False: 29537, True: 444}]\n",
      "[2025-07-03 19:29:13,556: INFO: 946721898:     had_incident: {False: 25814, True: 4167}]\n",
      "[2025-07-03 19:29:13,556: INFO: 946721898:     safety_car_lap: {False: 15411, True: 14570}]\n",
      "[2025-07-03 19:29:13,570: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:16,243: INFO: 946721898: Updated laps_transformed with 29981 rows]\n",
      "[2025-07-03 19:29:16,245: INFO: 946721898: Successfully transformed and updated laps]\n",
      "[2025-07-03 19:29:16,246: INFO: 946721898: Transforming table: pit_stops]\n",
      "[2025-07-03 19:29:16,248: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:16,254: INFO: 946721898: Transforming pit_stops with 4206 rows]\n",
      "[2025-07-03 19:29:16,255: INFO: 946721898: Handling missing values in pit_stops]\n",
      "[2025-07-03 19:29:16,257: INFO: 946721898: Fixing data types in pit_stops]\n",
      "[2025-07-03 19:29:16,257: INFO: 946721898: Handling outliers in pit_stops with F1 context]\n",
      "[2025-07-03 19:29:16,258: INFO: 946721898: Encoding categorical variables in pit_stops]\n",
      "[2025-07-03 19:29:16,261: INFO: 946721898: DEBUG pit_stops:]\n",
      "[2025-07-03 19:29:16,261: INFO: 946721898:   Shape: (4206, 13)]\n",
      "[2025-07-03 19:29:16,261: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'lap_number', 'pit_duration', 'created_at', 'is_outlier', 'pit_stop_count', 'pit_stop_timing', 'normal_pit_stop', 'long_pit_stop', 'penalty_pit_stop']]\n",
      "[2025-07-03 19:29:16,262: INFO: 946721898:   Missing values: 1025]\n",
      "[2025-07-03 19:29:16,262: INFO: 946721898:   Boolean columns: ['is_outlier', 'normal_pit_stop', 'long_pit_stop', 'penalty_pit_stop']]\n",
      "[2025-07-03 19:29:16,262: INFO: 946721898:     is_outlier: {False: 4067, True: 139}]\n",
      "[2025-07-03 19:29:16,263: INFO: 946721898:     normal_pit_stop: {False: 4206}]\n",
      "[2025-07-03 19:29:16,263: INFO: 946721898:     long_pit_stop: {False: 2978, True: 1228}]\n",
      "[2025-07-03 19:29:16,263: INFO: 946721898:     penalty_pit_stop: {True: 2978, False: 1228}]\n",
      "[2025-07-03 19:29:16,266: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:16,619: INFO: 946721898: Updated pit_stops_transformed with 4206 rows]\n",
      "[2025-07-03 19:29:16,620: INFO: 946721898: Successfully transformed and updated pit_stops]\n",
      "[2025-07-03 19:29:16,620: INFO: 946721898: Transforming table: stints]\n",
      "[2025-07-03 19:29:16,623: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:16,631: INFO: 946721898: Transforming stints with 4522 rows]\n",
      "[2025-07-03 19:29:16,631: INFO: 946721898: Handling missing values in stints]\n",
      "[2025-07-03 19:29:16,636: WARNING: 946721898: Could not impute compound in stints: 2]\n",
      "[2025-07-03 19:29:16,641: INFO: 946721898: Fixing data types in stints]\n",
      "[2025-07-03 19:29:16,643: INFO: 946721898: Handling outliers in stints with F1 context]\n",
      "[2025-07-03 19:29:16,646: INFO: 946721898: Encoding categorical variables in stints]\n",
      "[2025-07-03 19:29:16,648: INFO: 946721898: DEBUG stints:]\n",
      "[2025-07-03 19:29:16,649: INFO: 946721898:   Shape: (4522, 12)]\n",
      "[2025-07-03 19:29:16,649: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'compound', 'lap_start', 'lap_end', 'tyre_age_at_start', 'created_at', 'is_outlier', 'stint_duration', 'tire_age_progression']]\n",
      "[2025-07-03 19:29:16,650: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:16,650: INFO: 946721898:   Boolean columns: ['is_outlier']]\n",
      "[2025-07-03 19:29:16,650: INFO: 946721898:     is_outlier: {False: 3360, True: 1162}]\n",
      "[2025-07-03 19:29:16,653: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:16,987: INFO: 946721898: Updated stints_transformed with 4522 rows]\n",
      "[2025-07-03 19:29:16,988: INFO: 946721898: Successfully transformed and updated stints]\n",
      "[2025-07-03 19:29:16,988: INFO: 946721898: Transforming table: positions]\n",
      "[2025-07-03 19:29:16,990: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:17,046: INFO: 946721898: Transforming positions with 36834 rows]\n",
      "[2025-07-03 19:29:17,047: INFO: 946721898: Handling missing values in positions]\n",
      "[2025-07-03 19:29:17,050: INFO: 946721898: Fixing data types in positions]\n",
      "[2025-07-03 19:29:17,053: INFO: 946721898: Handling outliers in positions with F1 context]\n",
      "[2025-07-03 19:29:17,054: INFO: 946721898: Encoding categorical variables in positions]\n",
      "[2025-07-03 19:29:17,057: INFO: 946721898: DEBUG positions:]\n",
      "[2025-07-03 19:29:17,057: INFO: 946721898:   Shape: (36834, 13)]\n",
      "[2025-07-03 19:29:17,058: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'position', 'date', 'created_at', 'is_outlier', 'position_change', 'position_std', 'is_leader', 'position_improved', 'position_declined']]\n",
      "[2025-07-03 19:29:17,059: INFO: 946721898:   Missing values: 1061]\n",
      "[2025-07-03 19:29:17,059: INFO: 946721898:   Boolean columns: ['is_outlier', 'is_leader', 'position_improved', 'position_declined']]\n",
      "[2025-07-03 19:29:17,059: INFO: 946721898:     is_outlier: {False: 36834}]\n",
      "[2025-07-03 19:29:17,060: INFO: 946721898:     is_leader: {False: 36050, True: 784}]\n",
      "[2025-07-03 19:29:17,060: INFO: 946721898:     position_improved: {False: 30334, True: 6500}]\n",
      "[2025-07-03 19:29:17,061: INFO: 946721898:     position_declined: {True: 29275, False: 7559}]\n",
      "[2025-07-03 19:29:17,063: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:19,860: INFO: 946721898: Updated positions_transformed with 36834 rows]\n",
      "[2025-07-03 19:29:19,863: INFO: 946721898: Successfully transformed and updated positions]\n",
      "[2025-07-03 19:29:19,863: INFO: 946721898: Transforming table: intervals]\n",
      "[2025-07-03 19:29:19,866: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:20,359: INFO: 946721898: Transforming intervals with 288343 rows]\n",
      "[2025-07-03 19:29:20,360: INFO: 946721898: Handling missing values in intervals]\n",
      "[2025-07-03 19:29:20,405: INFO: 946721898: Fixing data types in intervals]\n",
      "[2025-07-03 19:29:20,408: INFO: 946721898: Handling outliers in intervals with F1 context]\n",
      "[2025-07-03 19:29:20,412: INFO: 946721898: Encoding categorical variables in intervals]\n",
      "[2025-07-03 19:29:20,413: INFO: 946721898: DEBUG intervals:]\n",
      "[2025-07-03 19:29:20,413: INFO: 946721898:   Shape: (288343, 11)]\n",
      "[2025-07-03 19:29:20,413: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'gap_to_leader', 'interval', 'date', 'created_at', 'is_outlier', 'is_leader', 'is_lapped']]\n",
      "[2025-07-03 19:29:20,415: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:20,416: INFO: 946721898:   Boolean columns: ['is_outlier', 'is_leader', 'is_lapped']]\n",
      "[2025-07-03 19:29:20,417: INFO: 946721898:     is_outlier: {False: 288343}]\n",
      "[2025-07-03 19:29:20,417: INFO: 946721898:     is_leader: {False: 287584, True: 759}]\n",
      "[2025-07-03 19:29:20,418: INFO: 946721898:     is_lapped: {False: 288189, True: 154}]\n",
      "[2025-07-03 19:29:20,423: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:41,832: INFO: 946721898: Updated intervals_transformed with 288343 rows]\n",
      "[2025-07-03 19:29:41,847: INFO: 946721898: Successfully transformed and updated intervals]\n",
      "[2025-07-03 19:29:41,847: INFO: 946721898: Transforming table: weather]\n",
      "[2025-07-03 19:29:41,850: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:41,859: INFO: 946721898: Transforming weather with 5119 rows]\n",
      "[2025-07-03 19:29:41,859: INFO: 946721898: Handling missing values in weather]\n",
      "[2025-07-03 19:29:41,863: INFO: 946721898: Fixing data types in weather]\n",
      "[2025-07-03 19:29:41,865: INFO: 946721898: Handling outliers in weather with F1 context]\n",
      "[2025-07-03 19:29:41,868: INFO: 946721898: Encoding categorical variables in weather]\n",
      "[2025-07-03 19:29:41,869: INFO: 946721898: DEBUG weather:]\n",
      "[2025-07-03 19:29:41,869: INFO: 946721898:   Shape: (5119, 13)]\n",
      "[2025-07-03 19:29:41,870: INFO: 946721898:   Columns: ['id', 'session_key', 'meeting_key', 'air_temperature', 'track_temperature', 'humidity', 'rainfall', 'date', 'created_at', 'is_outlier', 'temperature_delta', 'weather_severity', 'extreme_weather']]\n",
      "[2025-07-03 19:29:41,870: INFO: 946721898:   Missing values: 0]\n",
      "[2025-07-03 19:29:41,874: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,251: INFO: 946721898: Updated weather_transformed with 5119 rows]\n",
      "[2025-07-03 19:29:42,252: INFO: 946721898: Successfully transformed and updated weather]\n",
      "[2025-07-03 19:29:42,254: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,257: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,260: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,345: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,355: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,365: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,444: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "[2025-07-03 19:29:42,977: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "=== DATA TRANSFORMATION RESULTS (Database-First) ===\n",
      "Transformed Tables: 8\n",
      "\n",
      "SESSIONS:\n",
      "  Rows: 53\n",
      "  Columns: 8\n",
      "  Missing Values: 0\n",
      "  New Features: 1\n",
      "    ['session_type_encoded']...\n",
      "\n",
      "DRIVERS:\n",
      "  Rows: 1059\n",
      "  Columns: 8\n",
      "  Missing Values: 0\n",
      "  New Features: 1\n",
      "    ['team_name_encoded']...\n",
      "\n",
      "LAPS:\n",
      "  Rows: 29981\n",
      "  Columns: 19\n",
      "  Missing Values: 0\n",
      "  New Features: 5\n",
      "    ['lap_time_std', 'lap_time_mean', 'lap_time_deviation', 'had_incident', 'safety_car_lap']...\n",
      "  Outliers: 444 (1.5%)\n",
      "\n",
      "PIT_STOPS:\n",
      "  Rows: 4206\n",
      "  Columns: 13\n",
      "  Missing Values: 0\n",
      "  Outliers: 139 (3.3%)\n",
      "\n",
      "STINTS:\n",
      "  Rows: 4522\n",
      "  Columns: 12\n",
      "  Missing Values: 0\n",
      "  Outliers: 1162 (25.7%)\n",
      "\n",
      "POSITIONS:\n",
      "  Rows: 36834\n",
      "  Columns: 13\n",
      "  Missing Values: 0\n",
      "  New Features: 2\n",
      "    ['position_std', 'is_leader']...\n",
      "  Outliers: 0 (0.0%)\n",
      "\n",
      "INTERVALS:\n",
      "  Rows: 288343\n",
      "  Columns: 11\n",
      "  Missing Values: 0\n",
      "  New Features: 1\n",
      "    ['is_leader']...\n",
      "  Outliers: 0 (0.0%)\n",
      "\n",
      "WEATHER:\n",
      "  Rows: 5119\n",
      "  Columns: 12\n",
      "  Missing Values: 0\n",
      "\n",
      "Total Feature Columns for ML: 52\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_manager = ConfigurationManager()\n",
    "transformation_config = config_manager.get_data_transformation_config()\n",
    "db_config = DatabaseConfig()\n",
    "\n",
    "# Create transformation instance\n",
    "data_transformation = DataTransformation(transformation_config, db_config)\n",
    "\n",
    "# Run transformation (updates database)\n",
    "transformed_data = data_transformation.transform_all_data()\n",
    "\n",
    "# Print results\n",
    "print(\"=== DATA TRANSFORMATION RESULTS (Database-First) ===\")\n",
    "print(f\"Transformed Tables: {len(transformed_data)}\")\n",
    "\n",
    "for table_name, df in transformed_data.items():\n",
    "    print(f\"\\n{table_name.upper()}:\")\n",
    "    print(f\"  Rows: {len(df)}\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")\n",
    "    print(f\"  Missing Values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Show new features\n",
    "    new_features = [col for col in df.columns if any(suffix in col for suffix in ['_std', '_mean', '_deviation', 'had_incident', 'safety_car_lap', 'is_leader', 'is_retired', '_encoded'])]\n",
    "    if new_features:\n",
    "        print(f\"  New Features: {len(new_features)}\")\n",
    "        print(f\"    {new_features[:5]}...\")  # Show first 5\n",
    "    \n",
    "    # Show outlier information\n",
    "    if 'is_outlier' in df.columns:\n",
    "        outlier_count = df['is_outlier'].sum()\n",
    "        print(f\"  Outliers: {outlier_count} ({outlier_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Get feature columns for ML\n",
    "feature_columns = data_transformation.get_feature_columns()\n",
    "print(f\"\\nTotal Feature Columns for ML: {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:50:05,305: INFO: data_ingestion: Successfully connected to PostgreSQL database]\n",
      "\n",
      "============================================================\n",
      "TABLE: SESSIONS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 8)\n",
      "Columns: ['session_key', 'meeting_key', 'session_name', 'session_type', 'date_start', 'date_end', 'created_at', 'session_type_encoded']\n",
      "\n",
      "First 5 rows:\n",
      " session_key  meeting_key session_name session_type          date_start            date_end                 created_at  session_type_encoded\n",
      "        9974         1261   Practice 3     Practice 2025-05-24 10:30:00 2025-05-24 11:30:00 2025-07-04 11:51:27.876505                     0\n",
      "        9975         1261   Qualifying   Qualifying 2025-05-24 14:00:00 2025-05-24 15:00:00 2025-07-04 11:51:27.876505                     1\n",
      "        9979         1261         Race         Race 2025-05-25 13:00:00 2025-05-25 15:00:00 2025-07-04 11:51:27.876505                     2\n",
      "        9964         1262   Practice 1     Practice 2025-05-30 11:30:00 2025-05-30 12:30:00 2025-07-04 11:52:09.977048                     0\n",
      "        9965         1262   Practice 2     Practice 2025-05-30 15:00:00 2025-05-30 16:00:00 2025-07-04 11:52:09.977048                     0\n",
      "\n",
      "Feature columns: ['session_type_encoded']\n",
      "Feature values (first 5 rows):\n",
      " session_type_encoded\n",
      "                    0\n",
      "                    1\n",
      "                    2\n",
      "                    0\n",
      "                    0\n",
      "\n",
      "============================================================\n",
      "TABLE: DRIVERS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 8)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'full_name', 'team_name', 'created_at', 'team_name_encoded']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number         full_name       team_name                 created_at  team_name_encoded\n",
      "  1         9686         1254              1    Max VERSTAPPEN Red Bull Racing 2025-07-04 11:46:47.203057                  8\n",
      "  2         9686         1254              4      Lando NORRIS         McLaren 2025-07-04 11:46:47.203057                  5\n",
      "  3         9686         1254              5 Gabriel BORTOLETO     Kick Sauber 2025-07-04 11:46:47.203057                  4\n",
      "  4         9686         1254              6      Isack HADJAR    Racing Bulls 2025-07-04 11:46:47.203057                  7\n",
      "  5         9686         1254              7       Jack DOOHAN          Alpine 2025-07-04 11:46:47.203057                  0\n",
      "\n",
      "Feature columns: ['team_name_encoded']\n",
      "Feature values (first 5 rows):\n",
      " team_name_encoded\n",
      "                 8\n",
      "                 5\n",
      "                 4\n",
      "                 7\n",
      "                 0\n",
      "\n",
      "============================================================\n",
      "TABLE: LAPS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 19)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'lap_number', 'lap_duration', 'duration_sector_1', 'duration_sector_2', 'duration_sector_3', 'is_pit_out_lap', 'created_at', 'lap_time_std', 'lap_time_mean', 'lap_time_deviation', 'total_sector_time', 'sector_consistency', 'had_incident', 'safety_car_lap', 'is_outlier']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number  lap_number  ...  total_sector_time  sector_consistency  had_incident  safety_car_lap  is_outlier\n",
      "  1         9686         1254             27           1  ...            109.506           19.944572         False            True       False\n",
      "  2         9686         1254              6           1  ...            114.270           13.338881         False            True       False\n",
      "  3         9686         1254              4           1  ...             92.184           10.519434         False            True       False\n",
      "  4         9686         1254              5           1  ...            122.622           16.680794          True           False       False\n",
      "  5         9686         1254             10           1  ...            109.445           15.271008         False            True       False\n",
      "\n",
      "Feature columns: ['lap_time_std', 'lap_time_mean', 'lap_time_deviation', 'had_incident', 'safety_car_lap']\n",
      "Feature values (first 5 rows):\n",
      " lap_time_std  lap_time_mean  lap_time_deviation  had_incident  safety_car_lap\n",
      "    72.925171     102.121559           -9.122561         False            True\n",
      "    67.623802     104.094177           10.175825         False            True\n",
      "    70.102608     102.911491           -9.912492         False            True\n",
      "    72.820969     104.180443           18.441557          True           False\n",
      "    65.119644     104.810143            4.634856         False            True\n",
      "\n",
      "============================================================\n",
      "TABLE: PIT_STOPS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 13)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'lap_number', 'pit_duration', 'created_at', 'pit_stop_count', 'pit_stop_timing', 'normal_pit_stop', 'long_pit_stop', 'penalty_pit_stop', 'is_outlier']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number  lap_number  ...  pit_stop_timing normal_pit_stop  long_pit_stop  penalty_pit_stop  is_outlier\n",
      "  1         9686         1254             27           1  ...                0           False          False              True       False\n",
      "  2         9686         1254              6           1  ...                0           False          False              True       False\n",
      "  3         9686         1254              4           1  ...                0           False          False              True       False\n",
      "  4         9686         1254              5           1  ...                0           False          False              True       False\n",
      "  5         9686         1254             10           1  ...                0           False          False              True       False\n",
      "\n",
      "Feature columns: ['pit_stop_count', 'pit_stop_timing', 'normal_pit_stop', 'long_pit_stop', 'penalty_pit_stop']\n",
      "Feature values (first 5 rows):\n",
      " pit_stop_count  pit_stop_timing  normal_pit_stop  long_pit_stop  penalty_pit_stop\n",
      "              1                0            False          False              True\n",
      "              1                0            False          False              True\n",
      "              1                0            False          False              True\n",
      "              1                0            False          False              True\n",
      "              1                0            False          False              True\n",
      "\n",
      "============================================================\n",
      "TABLE: STINTS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 12)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'compound', 'lap_start', 'lap_end', 'tyre_age_at_start', 'created_at', 'stint_duration', 'tire_age_progression', 'is_outlier']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number compound  ...  tyre_age_at_start                 created_at  stint_duration tire_age_progression  is_outlier\n",
      "  1         9686         1254             27   MEDIUM  ...                  0 2025-07-04 11:46:47.203057               1                    0       False\n",
      "  2         9686         1254             23   MEDIUM  ...                  0 2025-07-04 11:46:47.203057               3                    0       False\n",
      "  3         9686         1254              5   MEDIUM  ...                  0 2025-07-04 11:46:47.203057               5                    0       False\n",
      "  4         9686         1254             22   MEDIUM  ...                  0 2025-07-04 11:46:47.203057               5                    0       False\n",
      "  5         9686         1254             81   MEDIUM  ...                  0 2025-07-04 11:46:47.203057               5                    0       False\n",
      "\n",
      "============================================================\n",
      "TABLE: POSITIONS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 13)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'position', 'date', 'created_at', 'position_change', 'position_std', 'is_leader', 'position_improved', 'position_declined', 'is_outlier']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number  position  ... position_std is_leader  position_improved  position_declined  is_outlier\n",
      "  1         9686         1254              1         1  ...     2.323578      True              False              False       False\n",
      "  2         9686         1254              4         2  ...     3.227746     False              False              False       False\n",
      "  3         9686         1254              5         3  ...     5.444298     False              False              False       False\n",
      "  4         9686         1254              6         4  ...     3.491764     False              False              False       False\n",
      "  5         9686         1254              7         5  ...     4.015914     False              False              False       False\n",
      "\n",
      "Feature columns: ['position_change', 'position_std', 'is_leader']\n",
      "Feature values (first 5 rows):\n",
      " position_change  position_std  is_leader\n",
      "               0      2.323578       True\n",
      "               0      3.227746      False\n",
      "               0      5.444298      False\n",
      "               0      3.491764      False\n",
      "               0      4.015914      False\n",
      "\n",
      "============================================================\n",
      "TABLE: INTERVALS_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 11)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'driver_number', 'gap_to_leader', 'interval', 'date', 'created_at', 'is_leader', 'is_lapped', 'is_outlier']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  driver_number  gap_to_leader  ...                    date                 created_at is_leader  is_lapped  is_outlier\n",
      "  1         9693         1254              4          0.000  ... 2025-03-16 03:07:28.621 2025-07-04 11:46:47.203057      True      False       False\n",
      "  2         9693         1254              1          0.061  ... 2025-03-16 04:18:31.343 2025-07-04 11:46:47.203057     False      False       False\n",
      "  3         9693         1254             81          0.104  ... 2025-03-16 04:18:31.403 2025-07-04 11:46:47.203057     False      False       False\n",
      "  4         9693         1254             63          0.483  ... 2025-03-16 04:18:31.867 2025-07-04 11:46:47.203057     False      False       False\n",
      "  5         9693         1254             22          0.568  ... 2025-03-16 04:18:31.937 2025-07-04 11:46:47.203057     False      False       False\n",
      "\n",
      "Feature columns: ['is_leader']\n",
      "Feature values (first 5 rows):\n",
      " is_leader\n",
      "      True\n",
      "     False\n",
      "     False\n",
      "     False\n",
      "     False\n",
      "\n",
      "============================================================\n",
      "TABLE: WEATHER_TRANSFORMED\n",
      "============================================================\n",
      "Shape: (5, 12)\n",
      "Columns: ['id', 'session_key', 'meeting_key', 'air_temperature', 'track_temperature', 'humidity', 'rainfall', 'date', 'created_at', 'temperature_delta', 'weather_severity', 'extreme_weather']\n",
      "\n",
      "First 5 rows:\n",
      " id  session_key  meeting_key  air_temperature  track_temperature  ...                    date                 created_at temperature_delta weather_severity  extreme_weather\n",
      "  1         9686         1254             23.8               39.3  ... 2025-03-14 01:16:12.694 2025-07-04 11:46:47.203057              15.5              0.0            False\n",
      "  2         9686         1254             24.0               39.2  ... 2025-03-14 01:17:12.684 2025-07-04 11:46:47.203057              15.2              0.0            False\n",
      "  3         9686         1254             24.0               39.4  ... 2025-03-14 01:18:12.709 2025-07-04 11:46:47.203057              15.4              0.0            False\n",
      "  4         9686         1254             24.0               40.1  ... 2025-03-14 01:19:12.698 2025-07-04 11:46:47.203057              16.1              0.0            False\n",
      "  5         9686         1254             24.1               40.1  ... 2025-03-14 01:20:12.707 2025-07-04 11:46:47.203057              16.0              0.0            False\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "sessions_transformed: 55 rows\n",
      "drivers_transformed: 1,099 rows\n",
      "laps_transformed: 31,023 rows\n",
      "pit_stops_transformed: 4,391 rows\n",
      "stints_transformed: 4,707 rows\n",
      "positions_transformed: 38,150 rows\n",
      "intervals_transformed: 288,343 rows\n",
      "weather_transformed: 5,281 rows\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows of each transformed table\n",
    "from src.formula_one.entity.config_entity import DatabaseConfig\n",
    "from src.formula_one.components.data_ingestion import DatabaseIngestion\n",
    "import pandas as pd\n",
    "\n",
    "# Create database connection\n",
    "db_config = DatabaseConfig()\n",
    "db_ingestion = DatabaseIngestion(None, db_config, None)\n",
    "conn = db_ingestion.connect_to_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    conn.rollback()\n",
    "    \n",
    "    # List of transformed tables\n",
    "    transformed_tables = [\n",
    "        \"sessions_transformed\", \"drivers_transformed\",\n",
    "        \"laps_transformed\", \"pit_stops_transformed\", \"stints_transformed\", \n",
    "        \"positions_transformed\", \"intervals_transformed\", \"weather_transformed\",\n",
    "    ]\n",
    "    \n",
    "    for table in transformed_tables:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TABLE: {table.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Get first 5 rows\n",
    "            cursor.execute(f\"SELECT * FROM {table} LIMIT 5\")\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "            if data:\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {list(df.columns)}\")\n",
    "                print(\"\\nFirst 5 rows:\")\n",
    "                print(df.to_string(index=False, max_cols=10))\n",
    "                \n",
    "                # Show feature columns specifically\n",
    "                feature_cols = [col for col in df.columns if any(suffix in col for suffix in \n",
    "                    ['_std', '_mean', '_deviation', 'had_incident', 'safety_car_lap', \n",
    "                     'is_leader', 'is_retired', '_encoded', '_count', '_timing', \n",
    "                     '_change', 'normal_', 'long_', 'penalty_', 'system_error'])]\n",
    "                \n",
    "                if feature_cols:\n",
    "                    print(f\"\\nFeature columns: {feature_cols}\")\n",
    "                    print(\"Feature values (first 5 rows):\")\n",
    "                    print(df[feature_cols].head().to_string(index=False))\n",
    "            else:\n",
    "                print(\"Table is empty\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {table}: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Summary of all tables\n",
    "    for table in transformed_tables:\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"{table}: {count:,} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"{table}: Error - {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
